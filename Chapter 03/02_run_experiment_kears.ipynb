{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "exp = Experiment(workspace=ws, name=\"cifar10_cnn_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'outputs')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Save model and weights with checkpoint callback\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint_cb = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), 'code'))\n",
    "\n",
    "from keras_azure_ml_cb import AzureMlKerasCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 37s 739us/step - loss: 2.0104 - accuracy: 0.2611 - val_loss: 1.7679 - val_accuracy: 0.4010\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 33s 659us/step - loss: 1.7250 - accuracy: 0.3736 - val_loss: 1.5813 - val_accuracy: 0.4470\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 33s 660us/step - loss: 1.5994 - accuracy: 0.4199 - val_loss: 1.4700 - val_accuracy: 0.4837\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 33s 655us/step - loss: 1.5167 - accuracy: 0.4523 - val_loss: 1.4154 - val_accuracy: 0.4992\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 33s 656us/step - loss: 1.4573 - accuracy: 0.4752 - val_loss: 1.3469 - val_accuracy: 0.5308\n",
      "10000/10000 [==============================] - 2s 184us/step\n",
      "Test loss: 1.3469151679992675\n",
      "Test accuracy: 0.5307999849319458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Tfkeras will be deprecated soon. Use Model.Framework.TENSORFLOW instead.\n"
     ]
    }
   ],
   "source": [
    "# Create a run\n",
    "with exp.start_logging(snapshot_directory='.') as run:\n",
    "\n",
    "    # Create an Azure Machine Learning monitor callback\n",
    "    azureml_cb = AzureMlKerasCallback(run)\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=True,\n",
    "            callbacks=[azureml_cb, checkpoint_cb])\n",
    "\n",
    "    # Load the best model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Score trained model\n",
    "    scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', scores[0])\n",
    "    run.log('Test loss', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    run.log('Test accuracy', scores[1])\n",
    "\n",
    "    # Upload the best model\n",
    "    run.upload_file(model_name, model_path)\n",
    "\n",
    "    # Register the best model\n",
    "    run.register_model(model_name, model_path=model_name, model_framework='TfKeras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
